import os
import re
import json
import csv
import xml.etree.ElementTree as ET
from html.parser import HTMLParser
from collections import Counter, deque

# Android-safe emoji poolï¼ˆå¯è‡ªå®šä¹‰æ‰©å……ï¼‰
EMOJI_POOL = [
    # åŠ¨ç‰©ä¸è‡ªç„¶
    "ğŸ¶", "ğŸ±", "ğŸ­", "ğŸ¹", "ğŸ°", "ğŸ¦Š", "ğŸ»", "ğŸ¼", "ğŸ¨", "ğŸ¯",
    "ğŸ¦", "ğŸ®", "ğŸ·", "ğŸ¸", "ğŸµ", "ğŸ¦„", "ğŸ”", "ğŸ§", "ğŸ¦", "ğŸ¤",
    "ğŸ", "ğŸ", "ğŸ¦‹", "ğŸ¢", "ğŸ", "ğŸ ", "ğŸ¬", "ğŸ³", "ğŸ¦‘", "ğŸ¦€",
    "ğŸŒ¸", "ğŸŒ»", "ğŸŒ¹", "ğŸŒº", "ğŸŒ¼", "ğŸŒ·", "ğŸŒ±", "ğŸŒ²", "ğŸŒ³", "ğŸŒ´",
    # é£Ÿç‰©ä¸é¥®æ–™
    "ğŸ", "ğŸ", "ğŸ", "ğŸŠ", "ğŸ‹", "ğŸŒ", "ğŸ‰", "ğŸ‡", "ğŸ“", "ğŸ«",
    "ğŸˆ", "ğŸ’", "ğŸ‘", "ğŸ¥­", "ğŸ", "ğŸ¥¥", "ğŸ¥", "ğŸ…", "ğŸ†", "ğŸ¥‘",
    "ğŸ¥¦", "ğŸ¥¬", "ğŸ¥•", "ğŸŒ½", "ğŸŒ¶ï¸", "ğŸ§„", "ğŸ§…", "ğŸ¥”", "ğŸ¥š", "ğŸ",
    "ğŸ¥", "ğŸ¥¯", "ğŸ¥¨", "ğŸ§€", "ğŸ¥“", "ğŸ—", "ğŸ–", "ğŸŒ­", "ğŸ”", "ğŸŸ",
    # æ´»åŠ¨
    "âš½", "ğŸ€", "ğŸˆ", "âš¾", "ğŸ¾", "ğŸ", "ğŸ‰", "ğŸ±", "ğŸ“", "ğŸ¸",
    "ğŸ¥…", "ğŸ’", "ğŸ‘", "ğŸ", "â›³", "ğŸ¹", "ğŸ£", "ğŸ¤¿", "ğŸ¥Š", "ğŸ¥‹",
    "ğŸ¯", "ğŸ³", "ğŸª", "ğŸ›¹", "ğŸ¥Œ", "ğŸ›·", "â›·ï¸", "ğŸ‚", "ğŸ„â€â™‚ï¸", "ğŸŠâ€â™€ï¸",
    "ğŸ®", "ğŸ²", "ğŸ§©", "ğŸ€„", "â™Ÿï¸", "ğŸƒ", "ğŸ§—", "ğŸ†", "ğŸ¥‡", "ğŸ¥ˆ", "ğŸ¥‰",
    # ç‰©ä½“
    "âŒš", "ğŸ“±", "ğŸ’»", "ğŸ–¨ï¸", "ğŸ•¹ï¸", "ğŸ®", "ğŸ“·", "ğŸ“¸", "ğŸ“¹", "ğŸ¥",
    "ğŸ“º", "ğŸ“»", "ğŸ™ï¸", "ğŸšï¸", "ğŸ›ï¸", "â˜ï¸", "ğŸ“", "ğŸ“Ÿ", "ğŸ“ ", "ğŸ”‹",
    "ğŸ”Œ", "ğŸ’¡", "ğŸ”¦", "ğŸ•¯ï¸", "ğŸ›¢ï¸", "ğŸ’°", "ğŸ’³", "ğŸ—ï¸", "ğŸ”‘", "ğŸšª",
    "ğŸ”’", "ğŸ”“", "ğŸ”‘", "ğŸ”", "ğŸ›¡ï¸", "ğŸ§²", "âš–ï¸", "ğŸ”—", "ğŸ§°", "ğŸ”§",
    "ğŸ”¨", "ğŸª“", "â›ï¸", "ğŸ› ï¸", "ğŸ—¡ï¸", "âš”ï¸", "ğŸ”«", "ğŸ¹", "ğŸ›ï¸", "ğŸ›‹ï¸",
    # æ—…è¡Œä¸åœ°ç‚¹
    "ğŸš—", "ğŸš•", "ğŸš™", "ğŸšŒ", "ğŸš", "ğŸï¸", "ğŸš“", "ğŸš‘", "ğŸš’", "ğŸš",
    "ğŸ›»", "ğŸšš", "ğŸš›", "ğŸšœ", "ğŸï¸", "ğŸ›µ", "ğŸš²", "ğŸ›´", "ğŸš¨", "ğŸš”",
    "ğŸš¦", "ğŸš§", "ğŸ›£ï¸", "ğŸ›¤ï¸", "âœˆï¸", "ğŸ›©ï¸", "ğŸš", "ğŸš€", "ğŸ›¸", "â›µ",
    "ğŸš¢", "ğŸ›³ï¸", "â›´ï¸", "ğŸš¤", "ğŸ›¥ï¸", "ğŸ—½", "ğŸ—¼", "ğŸ°", "ğŸ¯", "ğŸŒ‹",
    "ğŸ—»", "ğŸ•ï¸", "ğŸï¸", "ğŸœï¸", "ğŸï¸", "ğŸ–ï¸", "ğŸŸï¸", "ğŸ›ï¸", "ğŸ—ï¸",
    # äººç‰©
    "ğŸ˜€", "ğŸ˜ƒ", "ğŸ˜„", "ğŸ˜", "ğŸ˜†", "ğŸ˜…", "ğŸ˜‚", "ğŸ¤£", "ğŸ˜Š", "ğŸ˜‡",
    "ğŸ™‚", "ğŸ™ƒ", "ğŸ˜‰", "ğŸ˜Œ", "ğŸ˜", "ğŸ¥°", "ğŸ˜˜", "ğŸ˜—", "ğŸ˜™", "ğŸ˜š",
    "ğŸ˜‹", "ğŸ˜œ", "ğŸ˜", "ğŸ˜›", "ğŸ¤‘", "ğŸ¤—", "ğŸ¤©", "ğŸ¥³", "ğŸ˜", "ğŸ¤“",
    "ğŸ§", "ğŸ˜•", "ğŸ« ", "ğŸ˜Ÿ", "ğŸ™", "â˜¹ï¸", "ğŸ˜®", "ğŸ˜¯", "ğŸ˜²", "ğŸ˜³",
    "ğŸ¥º", "ğŸ˜¦", "ğŸ˜§", "ğŸ˜¨", "ğŸ˜°", "ğŸ˜¥", "ğŸ˜¢", "ğŸ˜­", "ğŸ˜±", "ğŸ˜–",
    "ğŸ˜£", "ğŸ˜", "ğŸ˜“", "ğŸ˜©", "ğŸ˜«", "ğŸ¥±", "ğŸ˜¤", "ğŸ˜¡", "ğŸ˜ ", "ğŸ¤¬",
    "ğŸ˜ˆ", "ğŸ‘¿", "ğŸ‘¹", "ğŸ‘º", "ğŸ’€", "â˜ ï¸", "ğŸ‘»", "ğŸ‘½", "ğŸ‘¾", "ğŸ¤–",
    "ğŸ‘‹", "ğŸ¤š", "ğŸ–ï¸", "âœ‹", "ğŸ––", "ğŸ‘Œ", "ğŸ¤Œ", "ğŸ¤", "âœŒï¸", "ğŸ¤",
    "ğŸ«°", "ğŸ¤Ÿ", "ğŸ¤˜", "ğŸ¤™", "ğŸ«µ", "ğŸ«¶", "ğŸ‘", "ğŸ¤²", "ğŸ™", "ğŸ‘",
    "ğŸ«¡", "ğŸ«¥", "ğŸ¤", "ğŸ‘", "ğŸ‘", "ğŸ‘Š", "âœŠ", "ğŸ‘ˆ", "ğŸ‘‰", "ğŸ‘†",
    "ğŸ–•", "ğŸ‘‡", "â˜ï¸", "ğŸ«³", "ğŸ«´", "ğŸ’ª", "ğŸ¦¾", "ğŸ¦¿", "ğŸ¦µ", "ğŸ¦¶",
    "ğŸ‘€", "ğŸ‘ï¸", "ğŸ‘…", "ğŸ‘„", "ğŸ§‘", "ğŸ‘¦", "ğŸ‘§", "ğŸ‘¨", "ğŸ‘©", "ğŸ§“",
    "ğŸ‘´", "ğŸ‘µ", "ğŸ§”", "ğŸ‘±â€â™‚ï¸", "ğŸ‘±â€â™€ï¸", "ğŸ‘¨â€ğŸ¦°", "ğŸ‘©â€ğŸ¦°", "ğŸ‘¨â€ğŸ¦±", "ğŸ‘©â€ğŸ¦±",
    # ç¬¦å·
    "â¤ï¸", "ğŸ§¡", "ğŸ’›", "ğŸ’š", "ğŸ’™", "ğŸ’œ", "ğŸ¤", "ğŸ–¤", "ğŸ¤", "ğŸ’”",
    "â£ï¸", "ğŸ’•", "ğŸ’", "ğŸ’“", "ğŸ’—", "ğŸ’–", "ğŸ’˜", "ğŸ’", "ğŸ’Ÿ", "â˜®ï¸",
    "âœï¸", "â˜ªï¸", "ğŸ•‰ï¸", "â˜¸ï¸", "âœ¡ï¸", "ğŸ”¯", "ğŸ•", "â˜¯ï¸", "â˜¦ï¸", "ğŸ›",
    "â›", "â™ˆ", "â™‰", "â™Š", "â™‹", "â™Œ", "â™", "â™", "â™", "â™", "â™‘", "â™’", "â™“",
    "ğŸ†—", "ğŸ†•", "ğŸ†™", "ğŸ†’", "ğŸ†“", "â„¹ï¸", "ğŸ†–", "ğŸ†š", "ğŸˆ", "ğŸˆ¯",
    "ğŸˆš", "ğŸˆ·ï¸", "ğŸˆ¶", "ğŸˆ¸", "ğŸˆ´", "ğŸˆ³", "ğŸˆ²", "ğŸ‰", "ğŸ‰‘", "ãŠ—ï¸", "ãŠ™ï¸",
    "ğŸˆ¹", "ğŸˆº", "ğŸˆµ", "ğŸ”", "ğŸ’¯", "ğŸ”¢", "ğŸ”¤", "ğŸ”¡", "ğŸ” ", "ğŸ†", "ğŸ…°ï¸", "ğŸ…±ï¸", "ğŸ…¾ï¸", "ğŸ…¿ï¸",
    "Â©ï¸", "Â®ï¸", "â„¢ï¸", "#ï¸âƒ£", "*ï¸âƒ£", "0ï¸âƒ£", "1ï¸âƒ£", "2ï¸âƒ£", "3ï¸âƒ£", "4ï¸âƒ£", "5ï¸âƒ£", "6ï¸âƒ£", "7ï¸âƒ£", "8ï¸âƒ£", "9ï¸âƒ£", "ğŸ”Ÿ",
    "ğŸ””", "ğŸ”•", "ğŸµ", "ğŸ¶", "ğŸ’¤", "ğŸ’¢", "ğŸ’¬", "ğŸ’­", "ğŸ—¯ï¸", "â™¨ï¸", "ğŸ’¦", "ğŸ’¨", "ğŸ’«", "ğŸ•³ï¸", "ğŸ’£", "ğŸ’¥", "ğŸš¨", "ğŸ’¦",
    "ğŸ’¡", "ğŸ”‘", "ğŸ”’", "ğŸ”“", "ğŸ”", "ğŸ”", "ğŸ›¡ï¸", "ğŸ§²", "ğŸ”—", "âš–ï¸", "ğŸ§°", "ğŸ”§", "ğŸ”¨", "ğŸª“", "â›ï¸", "ğŸ› ï¸", "ğŸ—¡ï¸", "âš”ï¸",
    "ğŸ”«", "ğŸ¹", "ğŸ›ï¸", "ğŸ›‹ï¸", "ğŸ›’", "ğŸ§º", "ğŸ§»", "ğŸ§¼", "ğŸª¥", "ğŸ§½", "ğŸª£", "ğŸ§´", "ğŸ§·", "ğŸ§¹", "ğŸª’", "ğŸ§¯", "ğŸ›ï¸"
]

EMOJI_REGEX = re.compile(
    r"("
    r"(?:[\U0001F1E6-\U0001F1FF]{2})|"  # flags
    r"(?:[\U0001F600-\U0001F64F])|"
    r"(?:[\U0001F300-\U0001F5FF])|"
    r"(?:[\U0001F680-\U0001F6FF])|"
    r"(?:[\U0001F700-\U0001F77F])|"
    r"(?:[\U0001F780-\U0001F7FF])|"
    r"(?:[\U0001F800-\U0001F8FF])|"
    r"(?:[\U0001F900-\U0001F9FF])|"
    r"(?:[\U0001FA00-\U0001FA6F])|"
    r"(?:[\U0001FA70-\U0001FAFF])|"
    r"(?:[\u2600-\u26FF])|"
    r"(?:[\u2700-\u27BF])|"
    r"(?:[\u2300-\u23FF])|"
    r"(?:[\u2B05-\u2B07])|"
    r"(?:\u200D)"
    r")+",
    re.UNICODE
)

SUPPORTED_EXTS = (".json", ".txt", ".md", ".csv", ".xml", ".html", ".htm")

def extract_emoji(text):
    # Find all emoji/sequence, keeping order, including duplicates
    return [m.group(0) for m in EMOJI_REGEX.finditer(text)]

def build_duplicate_emoji_mapping(emoji_list, emoji_pool):
    """
    ä¿ç•™æ¯ä¸ªemojié¦–æ¬¡å‡ºç°ä¸å˜ï¼Œä»…å¯¹é‡å¤å‡ºç°çš„emojiåšæ›¿æ¢ä¸ºpoolä¸­æœªç”¨è¿‡çš„emojiã€‚
    è‹¥emoji_poolç”¨å°½åˆ™å¾ªç¯ä½¿ç”¨ã€‚
    è¿”å›å­—å…¸ï¼š{åŸemoji: [None, æ›¿æ¢1, æ›¿æ¢2...]}ï¼ŒNoneè¡¨ç¤ºé¦–ä¸ªä¸æ¢ã€‚
    """
    counts = Counter(emoji_list)
    duplicates = {em for em, c in counts.items() if c > 1}
    # ç»Ÿè®¡æ¯ä¸ªemojiå‡ºç°äº†å‡ æ¬¡
    positions = {}
    for idx, em in enumerate(emoji_list):
        positions.setdefault(em, []).append(idx)
    # æ–°emojiåˆ†é…æ± 
    used = set(emoji_list)
    pool = deque([e for e in emoji_pool if e not in used])
    emoji_replace_map = {}
    for em in duplicates:
        occurrence = len(positions[em])
        repls = [None]  # ç¬¬ä¸€æ¬¡å‡ºç°ä¸æ›¿æ¢
        for _ in range(occurrence - 1):
            if not pool:
                pool = deque([e for e in emoji_pool if e not in used])
            if pool:
                new_em = pool.popleft()
                repls.append(new_em)
                pool.append(new_em)
            else:
                # çº¯ä¿é™©ï¼Œç†è®ºä¸ä¼šåˆ°è¿™é‡Œ
                repls.append(em)
        emoji_replace_map[em] = repls
    return emoji_replace_map, positions

def replace_duplicates_in_text(text, emoji_replace_map, positions):
    """
    ä»…æ›¿æ¢é‡å¤çš„emojiï¼Œç¬¬ä¸€æ¬¡å‡ºç°ä¿ç•™ï¼Œåç»­å‡ºç°æ‰æ¢ã€‚
    """
    matches = list(EMOJI_REGEX.finditer(text))
    # è®°å½•æ¯ä¸ªemojiå·²å‡ºç°æ¬¡æ•°
    occur_dict = {em:0 for em in emoji_replace_map}
    last_idx = 0
    result = []
    for m in matches:
        em = m.group(0)
        result.append(text[last_idx:m.start()])
        if em in emoji_replace_map:
            occur_dict[em] += 1
            # é¦–æ¬¡å‡ºç°ç”¨åŸemojiï¼Œåç»­ç”¨æ˜ å°„
            idx = occur_dict[em]
            repl = emoji_replace_map[em][idx-1]  # idx-1ï¼šç¬¬0æ¬¡None, ä»1å¼€å§‹æ›¿æ¢
            if repl is None:
                result.append(em)
            else:
                result.append(repl)
        else:
            result.append(em)
        last_idx = m.end()
    result.append(text[last_idx:])
    return ''.join(result)

def process_json_file(src, dst, emoji_replace_map, positions):
    with open(src, "r", encoding="utf-8") as f:
        data = json.load(f)
    def recursive(obj):
        if isinstance(obj, str):
            return replace_duplicates_in_text(obj, emoji_replace_map, positions)
        elif isinstance(obj, list):
            return [recursive(o) for o in obj]
        elif isinstance(obj, dict):
            return {k: recursive(v) for k, v in obj.items()}
        return obj
    data_new = recursive(data)
    with open(dst, "w", encoding="utf-8") as f:
        json.dump(data_new, f, ensure_ascii=False, indent=2)

def process_csv_file(src, dst, emoji_replace_map, positions):
    with open(src, "r", encoding="utf-8", newline='') as f:
        reader = list(csv.reader(f))
    new_rows = []
    for row in reader:
        new_row = [replace_duplicates_in_text(cell, emoji_replace_map, positions) for cell in row]
        new_rows.append(new_row)
    with open(dst, "w", encoding="utf-8", newline='') as f:
        writer = csv.writer(f)
        writer.writerows(new_rows)

def process_txt_file(src, dst, emoji_replace_map, positions):
    with open(src, "r", encoding="utf-8") as f:
        text = f.read()
    new_text = replace_duplicates_in_text(text, emoji_replace_map, positions)
    with open(dst, "w", encoding="utf-8") as f:
        f.write(new_text)

def process_md_file(src, dst, emoji_replace_map, positions):
    process_txt_file(src, dst, emoji_replace_map, positions)

def process_xml_file(src, dst, emoji_replace_map, positions):
    tree = ET.parse(src)
    root = tree.getroot()
    def recursive_xml(elem):
        if elem.text:
            elem.text = replace_duplicates_in_text(elem.text, emoji_replace_map, positions)
        if elem.tail:
            elem.tail = replace_duplicates_in_text(elem.tail, emoji_replace_map, positions)
        for child in elem:
            recursive_xml(child)
    recursive_xml(root)
    tree.write(dst, encoding="utf-8", xml_declaration=True)

class MyHTMLParser(HTMLParser):
    def __init__(self, emoji_replace_map, positions):
        super().__init__()
        self.emoji_replace_map = emoji_replace_map
        self.positions = positions
        self.result = []
    def handle_starttag(self, tag, attrs):
        attr_str = ''.join([f' {k}="{v}"' for k, v in attrs])
        self.result.append(f"<{tag}{attr_str}>")
    def handle_endtag(self, tag):
        self.result.append(f"</{tag}>")
    def handle_data(self, data):
        self.result.append(replace_duplicates_in_text(data, self.emoji_replace_map, self.positions))
    def handle_entityref(self, name):
        self.result.append(f"&{name};")
    def handle_charref(self, name):
        self.result.append(f"&#{name};")
    def get_html(self):
        return "".join(self.result)

def process_html_file(src, dst, emoji_replace_map, positions):
    with open(src, "r", encoding="utf-8") as f:
        text = f.read()
    parser = MyHTMLParser(emoji_replace_map, positions)
    parser.feed(text)
    with open(dst, "w", encoding="utf-8") as f:
        f.write(parser.get_html())

def main():
    src_dir = os.path.join(os.path.dirname(__file__))
    output_dir = os.path.join(src_dir, "output")
    os.makedirs(output_dir, exist_ok=True)
    files = [f for f in os.listdir(src_dir)
             if os.path.isfile(os.path.join(src_dir, f))
             and f.lower().endswith(SUPPORTED_EXTS)
             and not f.startswith("output")]
    for filename in files:
        src_path = os.path.join(src_dir, filename)
        dst_path = os.path.join(output_dir, filename)
        print(f"Processing {filename}")
        with open(src_path, "r", encoding="utf-8") as f:
            text = f.read()
        emoji_list = extract_emoji(text)
        if not emoji_list:
            print(f"  No emoji found in {filename}, skip.")
            continue
        emoji_replace_map, positions = build_duplicate_emoji_mapping(emoji_list, EMOJI_POOL)
        ext = os.path.splitext(filename)[-1].lower()
        if ext == ".json":
            process_json_file(src_path, dst_path, emoji_replace_map, positions)
        elif ext == ".txt":
            process_txt_file(src_path, dst_path, emoji_replace_map, positions)
        elif ext == ".md":
            process_md_file(src_path, dst_path, emoji_replace_map, positions)
        elif ext == ".csv":
            process_csv_file(src_path, dst_path, emoji_replace_map, positions)
        elif ext == ".xml":
            process_xml_file(src_path, dst_path, emoji_replace_map, positions)
        elif ext in (".html", ".htm"):
            process_html_file(src_path, dst_path, emoji_replace_map, positions)
        else:
            print(f"  Unsupported file type: {filename}")

if __name__ == "__main__":
    main()
