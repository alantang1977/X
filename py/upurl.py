import json
import requests
import warnings
import re
import os
import time
from urllib3.exceptions import InsecureRequestWarning
from copy import deepcopy
from concurrent.futures import ThreadPoolExecutor

# è‡ªå®šä¹‰ jsm.json çš„è·¯å¾„æˆ–ç½‘ç»œåœ°å€ï¼Œç•™ç©ºåˆ™ä½¿ç”¨å½“å‰ç›®å½•ä¸‹çš„ jsm.json
jsm_file_path = ""

# è¯»å– jsm.json æ–‡ä»¶
jsm_data = {}
if jsm_file_path:
    if jsm_file_path.startswith(("http://", "https://")):
        try:
            response = requests.get(jsm_file_path)
            jsm_data = response.json()
        except Exception as e:
            print(f"ä»Žç½‘ç»œè¯»å– jsm.json é…ç½®æ–‡ä»¶å¤±è´¥: {str(e)}")
    else:
        if os.path.exists(jsm_file_path):
            try:
                with open(jsm_file_path, 'r', encoding='utf-8') as f:
                    jsm_data = json.load(f)
            except Exception as e:
                print(f"è¯»å–æœ¬åœ° jsm.json é…ç½®æ–‡ä»¶å¤±è´¥: {str(e)}")
        else:
            print(f"æœ¬åœ° jsm.json æ–‡ä»¶ {jsm_file_path} ä¸å­˜åœ¨")
else:
    local_path = os.path.join(os.getcwd(), 'jsm.json')
    if os.path.exists(local_path):
        try:
            with open(local_path, 'r', encoding='utf-8') as f:
                jsm_data = json.load(f)
        except Exception as e:
            print(f"è¯»å–é»˜è®¤ jsm.json é…ç½®æ–‡ä»¶å¤±è´¥: {str(e)}")
    else:
        print("é»˜è®¤çš„ jsm.json æ–‡ä»¶ä¸å­˜åœ¨")

# ç«™ç‚¹æ˜ å°„å…³ç³»
site_mappings = {
    'ç«‹æ’­': 'libo', 'é—ªç”µ':'shandian', 'æ¬§å“¥': 'ouge', 'å°ç±³': 'xiaomi', 'å¤šå¤š': 'duoduo',
    'èœ¡ç¬”': 'labi', 'è‡³è‡»': 'zhizhen', 'æœ¨å¶':'mogg', 'å…­è¶£': 'liuqu', 'è™Žæ–‘': 'huban',
    'ä¸‹é¥­': 'xiafan', 'çŽ©å¶': 'wogg', 'æ˜Ÿå‰§ç¤¾':'star2', 'äºŒå°': 'xhww'
}

# ä»£ç†é…ç½®
proxy_config = {
    "enabled": False,
    "proxies": {
        "http": "http://127.0.0.1:7890",
        "https": "http://127.0.0.1:7890"
    }
}

# æ–‡ä»¶è·¯å¾„é…ç½®
file_path_config = {
    "input_dir": "",
    "output_dir": ""
}

# æ–°å¢žjsmæ˜ å°„é…ç½®
jsm_mapping = {
    "Libvio": "libo",
    "Xiaomi": "xiaomi",
    "yydsys": "duoduo",
    "èœ¡ç¬”ç½‘ç›˜": "labi",
    "çŽ©å¶ | èœ¡ç¬”": "labi",
    "è‡³è‡»|ç½‘ç›˜": "zhizhen",
    "Huban": "huban",
    "Wogg": "wogg",
    "Mogg": "mogg",
    "çŽ©å¶ | é—ªç”µuc": "shandian",
    "çŽ©å¶ | äºŒå°": "xhww",
    "çŽ©å¶ | å°ç±³": "xiaomi",
    "çŽ©å¶ | å¤šå¤š": "duoduo",
    "çŽ©å¶ | æœ¨å¶": "mogg",
    "çŽ©å¶gg": "wogg",
    "æ˜Ÿå‰§ç¤¾": "star2"
}

# éœ€è¦æ‹¼æŽ¥æœç´¢è·¯å¾„çš„ç«™ç‚¹é…ç½®
search_path_config = {
    'é—ªç”µ': '/index.php/vod/search.html?wd=ä»™å°æœ‰æ ‘',
    'æ¬§å“¥': '/index.php/vod/search.html?wd=ä»™å°æœ‰æ ‘',
    'å°ç±³': '/index.php/vod/search.html?wd=ä»™å°æœ‰æ ‘',
    'å¤šå¤š': '/index.php/vod/search.html?wd=ä»™å°æœ‰æ ‘',
    'èœ¡ç¬”': '/index.php/vod/search.html?wd=ä»™å°æœ‰æ ‘',
    'è‡³è‡»': '/index.php/vod/search.html?wd=ä»™å°æœ‰æ ‘',
    'å…­è¶£': '/index.php/vod/search.html?wd=ä»™å°æœ‰æ ‘',
    'è™Žæ–‘': '/index.php/vod/search.html?wd=ä»™å°æœ‰æ ‘',
    'ä¸‹é¥­': '/index.php/vod/search.html?wd=ä»™å°æœ‰æ ‘',
    'çŽ©å¶': '/vodsearch/-------------.html?wd=ä»™å°æœ‰æ ‘',
    'æœ¨å¶': '/index.php/vod/search.html?wd=ä»™å°æœ‰æ ‘',
    'äºŒå°': '/index.php/vod/search.html?wd=ä»™å°æœ‰æ ‘',
    'ç«‹æ’­': '/search/-------------.html?wd=ä»™å°æœ‰æ ‘&submit='
}

# å®šä¹‰éœ€è¦æ ¡éªŒå…³é”®å­—çš„ç«™ç‚¹åŠå…¶å…³é”®å­—
keyword_required_sites = {
    'é—ªç”µ': 'class="search-stat"',
    'æ¬§å“¥': 'class="search-stat"',
    'å°ç±³': 'class="search-stat"',
    'å¤šå¤š': 'class="search-stat"',
    'èœ¡ç¬”': 'class="search-stat"',
    'è‡³è‡»': 'class="search-stat"',
    'å…­è¶£': 'class="search-stat"',
    'è™Žæ–‘': 'class="search-stat"',
    'ä¸‹é¥­': 'class="search-stat"',
    'çŽ©å¶': 'class="search-stat"',
    'æœ¨å¶': 'class="search-stat"',
    'äºŒå°': 'class="search-stat"',
    'ç«‹æ’­': 'class="stui-screen"'
}

# æ–°å¢žå¯é€‰çš„URLåŠ æƒé…ç½®ï¼Œé»˜è®¤æƒé‡ä¸º50
url_weight_config = {
    "æœ¨å¶": {
        "https://aliii.deno.dev": 60,
        "http://149.88.87.72:5666": 60
    },
    "è‡³è‡»": {
        "http://www.xhww.net": 10,
        "http://xhww.net": 10
    },
    "ç«‹æ’­": {
        "https://libvio.mov": 60,
        "https://www.libvio.cc": 60
    }
}

# å…œåº•URLé…ç½®
fallback_url_config = {
    "ç«‹æ’­": [
        "https://libvio.mov",
        "https://www.libvio.cc",
        "https://libvio.la",
        "https://libvio.pro",
        "https://libvio.fun",
        "https://libvio.me",
        "https://libvio.in",
        "https://libvio.site",
        "https://libvio.art",
        "https://libvio.com",
        "https://libvio.vip",
        "https://libvio.pw",
        "https://libvio.link"
    ],
    "é—ªç”µ": [
        "http://1.95.79.193",
        "http://1.95.79.193:666"
    ],
    "æ¬§å“¥": [
        "https://woog.nxog.eu.org"
    ],
    "å°ç±³": [
        "http://www.54271.fun",
        "https://www.milvdou.fun",
        "http://www.54271.fun",
        "https://www.mucpan.cc",
        "https://mucpan.cc",
        "http://milvdou.fun"
    ],
    "å¤šå¤š": [
        "https://tv.yydsys.top",
        "https://tv.yydsys.cc",
        "https://tv.214521.xyz",
        "http://155.248.200.65"
    ],
    "èœ¡ç¬”": [
        "http://feimaoai.site",
        "https://feimao666.fun",
        "http://feimao888.fun"
    ],
    "è‡³è‡»": [
        "https://mihdr.top",
        "http://www.miqk.cc",
        "http://www.xhww.net",
        "http://xhww.net",
        "https://xiaomiai.site"
    ],
    "å…­è¶£": [
        "https://wp.0v.fit"
    ],
    "è™Žæ–‘": [
        "http://103.45.162.207:20720"
    ],
    "ä¸‹é¥­": [
        "http://txfpan.top",
        "http://www.xn--ghqy10g1w0a.xyz"
    ],
    "çŽ©å¶": [
        "https://wogg.xxooo.cf",
        "https://wogg.333232.xyz",
        "https://www.wogg.one",
        "https://www.wogg.lol",
        "https://www.wogg.net"
    ],
    "æœ¨å¶": [
        "https://tv.91muou.icu",
        "https://mo.666291.xyz",
        "https://mo.muouso.fun",
        "https://aliii.deno.dev",
        "http://149.88.87.72:5666"
    ],
    "æ˜Ÿå‰§ç¤¾": [
        "https://mlink.cc/520TV"
    ],
    "äºŒå°": [
        "https://xhww.net",
        "https://www.xhww.net"
    ]
}

# å…¨å±€çŠ¶æ€
last_site = None


def log_message(message, site_name=None, step="", max_error_length=80):
    """æ ¼å¼åŒ–æ—¥å¿—æ‰“å°"""
    global last_site

    status_emojis = {
        '[å¼€å§‹]': 'ðŸš€', '[æˆåŠŸ]': 'âœ…', '[å®Œæˆ]': 'ðŸŽ‰', '[å¤±è´¥]': 'âŒ',
        '[è¶…æ—¶]': 'â³', '[è­¦å‘Š]': 'âš ï¸', '[é”™è¯¯]': 'ðŸš¨', '[ä¿¡æ¯]': 'â„¹ï¸',
        '[é€‰æ‹©]': 'ðŸ”', '[è¿žæŽ¥å¤±è´¥]': 'ðŸ”Œ'
    }

    if site_name and site_name != last_site:
        print(f"\n{'âœ¨ ' + '=' * 38 + ' âœ¨'}")
        print(f"ðŸŒ [ç«™ç‚¹: {site_name}]")
        print(f"{'âœ¨ ' + '=' * 38 + ' âœ¨'}")
        last_site = site_name

    for status, emoji in status_emojis.items():
        if status in message:
            message = message.replace(status, f"{status} {emoji}")
            break
    else:
        message = f"{message} ðŸ“¢"

    # æˆªæ–­è¿‡é•¿çš„é”™è¯¯ä¿¡æ¯
    if "[è¿žæŽ¥å¤±è´¥]" in message or "[é”™è¯¯]" in message:
        if len(message) > max_error_length:
            message = message[:max_error_length] + "..."

    print(f"[{time.strftime('%Y-%m-%d %H:%M:%S')}] [{step}] {message}") if step else print(message)


def test_url(url, site_name=None):
    """å¢žå¼ºç‰ˆURLæµ‹è¯•å‡½æ•°"""
    search_path = search_path_config.get(site_name)
    test_url = url.strip() + search_path if search_path else url.strip()
    keyword = keyword_required_sites.get(site_name)

    session = requests.Session()
    adapter = requests.adapters.HTTPAdapter(max_retries=2)
    session.mount('http://', adapter)
    session.mount('https://', adapter)

    try:
        # ç›´æŽ¥è¯·æ±‚æµ‹è¯•
        response = session.get(
            test_url,
            timeout=7,
            verify=False,
            headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'}
        )

        if response.status_code == 200:
            latency = response.elapsed.total_seconds()
            has_keyword = keyword in response.text if keyword else True

            log_msg = f"ç›´æŽ¥è®¿é—®æˆåŠŸ | å»¶è¿Ÿ: {latency:.2f}s"
            if keyword:
                log_msg += f" | å…³é”®å­—: {'âœ…' if has_keyword else 'âŒ'}"

            log_message(f"[æˆåŠŸ] {test_url} {log_msg}", site_name, "URLæµ‹è¯•")
            return latency, has_keyword

        log_message(f"[å¤±è´¥] HTTPçŠ¶æ€ç  {response.status_code}", site_name, "URLæµ‹è¯•")
        return None, None

    except requests.RequestException as e:
        error_type = "[è¶…æ—¶]" if isinstance(e, requests.Timeout) else "[è¿žæŽ¥å¤±è´¥]"
        log_message(f"{error_type} {str(e)}", site_name, "URLæµ‹è¯•")

        # ä»£ç†é‡è¯•é€»è¾‘
        if proxy_config["enabled"]:
            try:
                response = session.get(
                    test_url,
                    timeout=7,
                    verify=False,
                    proxies=proxy_config["proxies"],
                    headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'}
                )
                if response.status_code == 200:
                    latency = response.elapsed.total_seconds()
                    has_keyword = keyword in response.text if keyword else True
                    log_message(f"[æˆåŠŸ] ä»£ç†è®¿é—®æˆåŠŸ | å»¶è¿Ÿ: {latency:.2f}s | å…³é”®å­—: {'âœ…' if has_keyword else 'âŒ'}",
                                site_name, "URLæµ‹è¯•")
                    return latency, has_keyword
            except Exception as proxy_e:
                log_message(f"[å¤±è´¥] ä»£ç†è®¿é—®é”™è¯¯: {str(proxy_e)}", site_name, "URLæµ‹è¯•")

        return None, None


def get_best_url(urls, site_name=None, existing_url=None):
    """ä¼˜åŒ–åŽçš„URLé€‰æ‹©ç®—æ³•"""
    if not isinstance(urls, list):
        return urls

    weights = url_weight_config.get(site_name, {})
    default_weight = 50
    sorted_urls = sorted([(url, weights.get(url, default_weight)) for url in urls],
                         key=lambda x: -x[1])

    def test_single_url(url_weight):
        url, weight = url_weight
        latency, has_keyword = test_url(url, site_name)
        if latency is not None:
            return {
                "url": url,
                "latency": latency,
                "has_keyword": has_keyword,
                "weight": weight,
                "score": (weight * 0.6) + ((1 / (latency + 0.1)) * 40)
            }
        return None

    with ThreadPoolExecutor() as executor:
        candidates = [result for result in executor.map(test_single_url, sorted_urls) if result]

    if not candidates:
        log_message(f"[è­¦å‘Š] æ— å¯ç”¨URLï¼Œä½¿ç”¨çŽ°æœ‰é…ç½®: {existing_url}" if existing_url else
                    "[é”™è¯¯] æ— å¯ç”¨URLä¸”æ— åŽ†å²é…ç½®", site_name, "URLé€‰æ‹©")
        return existing_url if existing_url else None

    # æŒ‰è¯„åˆ†æŽ’åºï¼šå…³é”®å­—å­˜åœ¨ > è¯„åˆ† > å»¶è¿Ÿ
    sorted_candidates = sorted(candidates,
                               key=lambda x: (-x['has_keyword'], -x['score'], x['latency']))

    log_message("å€™é€‰URLè¯„ä¼°ç»“æžœ:\n" + "\n".join(
        [f"{item['url']} | æƒé‡:{item['weight']} å»¶è¿Ÿ:{item['latency']:.2f}s è¯„åˆ†:{item['score']:.1f}"
         for item in sorted_candidates]), site_name, "URLé€‰æ‹©")

    best = sorted_candidates[0]
    log_message(f"[é€‰æ‹©] æœ€ä¼˜URL: {best['url']} (è¯„åˆ†: {best['score']:.1f})", site_name, "URLé€‰æ‹©")
    return best['url']


def get_star2_real_url(source_url):
    """æ”¹è¿›çš„æ˜Ÿå‰§ç¤¾çœŸå®žURLæå–"""
    try:
        response = requests.get(
            source_url,
            timeout=8,
            verify=False,
            headers={'Referer': 'https://mlink.cc/'}
        )
        if response.status_code == 200:
            # å¢žå¼ºç‰ˆæ­£åˆ™åŒ¹é…
            match = re.search(
                r'''(?i)(?:href|src|data-?url)=["'](https?://[^"']*?star2\.cn[^"']*)["']''',
                response.text
            )
            if match:
                real_url = match.group(1).strip().rstrip('/')
                log_message(f"[æˆåŠŸ] æå–çœŸå®žé“¾æŽ¥: {real_url}", "æ˜Ÿå‰§ç¤¾", "é“¾æŽ¥è§£æž")
                return real_url
        log_message("[å¤±è´¥] æœªæ‰¾åˆ°æœ‰æ•ˆé“¾æŽ¥", "æ˜Ÿå‰§ç¤¾", "é“¾æŽ¥è§£æž")
    except Exception as e:
        log_message(f"[é”™è¯¯] è§£æžå¤±è´¥: {str(e)}", "æ˜Ÿå‰§ç¤¾", "é“¾æŽ¥è§£æž")
    return None


def merge_url_data(*dicts):
    """æ•°æ®åˆå¹¶åŽ»é‡"""
    merged = {}
    for d in dicts:
        if not d: continue
        for site, urls in d.items():
            merged.setdefault(site, []).extend(urls if isinstance(urls, list) else [urls])
    return {k: list(dict.fromkeys(v)) for k, v in merged.items()}


def get_file_path(filename, is_input=True):
    """è·¯å¾„å¤„ç†å‡½æ•°"""
    base_dir = file_path_config.get("input_dir" if is_input else "output_dir", "")
    return os.path.join(base_dir or os.getcwd(), filename)


def load_existing_config():
    """åŠ è½½çŽ°æœ‰url.jsoné…ç½®"""
    url_path = get_file_path('url.json')
    if os.path.exists(url_path):
        try:
            with open(url_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            log_message(f"[é”™è¯¯] è¯»å–çŽ°æœ‰é…ç½®å¤±è´¥: {str(e)}", step="é…ç½®åŠ è½½")
    return {}


def get_api_urls():
    """ä»Žæœ¬åœ°æ–‡ä»¶èŽ·å–é“¾æŽ¥"""
    API_FILE_PATH = get_file_path('url.json')
    try:
        with open(API_FILE_PATH, 'r', encoding='utf-8') as f:
            api_data = json.load(f)
        print("æˆåŠŸè¯»å– url.json æ–‡ä»¶")

        # åŸºäºŽ jsm_mapping ç”Ÿæˆ url_mapping
        url_mapping = {key: api_data.get(value) for key, value in jsm_mapping.items()}

        print("ç”Ÿæˆçš„ url_mapping:", url_mapping)
        return url_mapping
    except FileNotFoundError:
        print("æœªæ‰¾åˆ° url.json æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„ã€‚")
    except json.JSONDecodeError:
        print("url.json æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶å†…å®¹ã€‚")
    return {}


def replace_urls(data, urls):
    """æ›¿æ¢ JSON æ•°æ®ä¸­çš„ URL"""
    # æ ¹æ® jsm_mapping è½¬æ¢ api_urls
    api_urls = {
        jsm_key: urls.get(jsm_value)
        for jsm_key, jsm_value in jsm_mapping.items()
    }

    sites = data.get('sites', [])
    replaced_count = 0

    for item in sites:
        if isinstance(item, dict):
            key = item.get('key')
            ext = item.get('ext')
            new_url = api_urls.get(key)
            old_url = None

            if new_url and isinstance(ext, str):
                parts = ext.split('$$$')
                if len(parts) > 1 and parts[1].strip().startswith('http'):
                    old_url = parts[1]
                    parts[1] = new_url
                    item['ext'] = '$$$'.join(parts)
                    replaced_count += 1
                    print(f"æˆåŠŸæ›¿æ¢ {key} çš„é“¾æŽ¥: {old_url} -> {new_url}")
                    if 'url' in item:
                        del item['url']  # åˆ é™¤ url å­—æ®µ

            if old_url and not new_url:
                print(f"æœªæˆåŠŸæ›¿æ¢ {key} çš„é“¾æŽ¥ï¼ŒåŽŸé“¾æŽ¥: {old_url}")
        else:
            print(f"è·³è¿‡éžå­—å…¸ç±»åž‹çš„ item: {item}")

    print(f"æ€»å…±æ›¿æ¢äº† {replaced_count} ä¸ªé“¾æŽ¥ã€‚")
    return data


def update_jsm_config(urls):
    """æ›´æ–°jsm.jsoné…ç½®æ–‡ä»¶ä¸­çš„URL"""
    global jsm_data
    if not jsm_data:
        log_message("[é”™è¯¯] jsm_data ä¸ºç©ºï¼Œæ— æ³•æ›´æ–°é…ç½®", step="é…ç½®æ›´æ–°")
        return False

    updated_jsm_data = replace_urls(deepcopy(jsm_data), urls)

    try:
        jsm_output_path = get_file_path('jsm.json', is_input=False)
        os.makedirs(os.path.dirname(jsm_output_path), exist_ok=True)
        with open(jsm_output_path, 'w', encoding='utf-8') as f:
            json.dump(updated_jsm_data, f, ensure_ascii=False, indent=4)

        log_message("[å®Œæˆ] jsm.json é…ç½®æ–‡ä»¶æ›´æ–°æˆåŠŸ", step="é…ç½®æ›´æ–°")
        return True
    except Exception as e:
        log_message(f"[é”™è¯¯] æ›´æ–° jsm.json é…ç½®æ–‡ä»¶å¤±è´¥: {str(e)}", step="é…ç½®æ›´æ–°")
        return False


def process_urls():
    """æ ¸å¿ƒå¤„ç†æµç¨‹"""
    log_message("[å¼€å§‹] å¯åŠ¨URLæ›´æ–°æµç¨‹", step="ä¸»æµç¨‹")

    # åŠ è½½çŽ°æœ‰é…ç½®
    existing_config = load_existing_config()
    reverse_site_mapping = {v: k for k, v in site_mappings.items()}

    # æ•°æ®æºå¤„ç†
    data_sources = []
    try:
        remote_data = requests.get(
            'https://github.catvod.com/https://raw.githubusercontent.com/celin1286/xiaosa/main/yuan.json',
            timeout=10
        ).json()
        data_sources.append(remote_data)
        log_message("[æˆåŠŸ] è¿œç¨‹æ•°æ®åŠ è½½å®Œæˆ", step="æ•°æ®æ”¶é›†")
    except Exception as e:
        log_message(f"[é”™è¯¯] è¿œç¨‹æ•°æ®èŽ·å–å¤±è´¥: {str(e)}", step="æ•°æ®æ”¶é›†")

    local_path = get_file_path('yuan.json')
    if os.path.exists(local_path):
        try:
            with open(local_path, 'r', encoding='utf-8') as f:
                data_sources.append(json.load(f))
                log_message("[æˆåŠŸ] æœ¬åœ°æ•°æ®åŠ è½½å®Œæˆ", step="æ•°æ®æ”¶é›†")
        except Exception as e:
            log_message(f"[é”™è¯¯] æœ¬åœ°æ•°æ®è¯»å–å¤±è´¥: {str(e)}", step="æ•°æ®æ”¶é›†")

    data_sources.append(fallback_url_config)
    merged_data = merge_url_data(*data_sources)

    # ç»“æžœå­˜å‚¨
    result = {'url': {}}
    stats = {'total': 0,'success': 0, 'failed': [], 'changed': []}

    for cn_name, urls in merged_data.items():
        stats['total'] += 1
        site_key = site_mappings.get(cn_name)
        existing_url = existing_config.get(site_key, '')

        if cn_name == 'æ˜Ÿå‰§ç¤¾':
            best_source = get_best_url(urls, cn_name, existing_url)
            final_url = get_star2_real_url(best_source) if best_source else existing_url
        else:
            final_url = get_best_url(urls, cn_name, existing_url) or existing_url

        if final_url:
            result['url'][site_key] = final_url
            if existing_url and existing_url != final_url:
                stats['changed'].append(f"{cn_name}: {existing_url} â†’ {final_url}")
                log_message(f"[æ›´æ–°] é…ç½®å˜æ›´æ£€æµ‹", cn_name, "ç»“æžœå¤„ç†")
            stats['success'] += 1
        else:
            stats['failed'].append(cn_name)
            log_message("[è­¦å‘Š] æ— å¯ç”¨URL", cn_name, "ç»“æžœå¤„ç†")

    # æ–‡ä»¶ä¿å­˜
    output_files = {
        'yuan.json': merged_data,
        'url.json': result['url']
    }

    for filename, data in output_files.items():
        try:
            path = get_file_path(filename, is_input=False)
            os.makedirs(os.path.dirname(path), exist_ok=True)
            with open(path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            log_message(f"[æˆåŠŸ] ä¿å­˜æ–‡ä»¶: {path}", step="æ•°æ®æŒä¹…åŒ–")
        except Exception as e:
            log_message(f"[é”™è¯¯] æ–‡ä»¶ä¿å­˜å¤±è´¥: {str(e)}", step="æ•°æ®æŒä¹…åŒ–")

    # æ–°å¢žjsmæ›´æ–°æµç¨‹
    log_message("[å¼€å§‹] å¯åŠ¨jsmé…ç½®æ›´æ–°", step="ä¸»æµç¨‹")
    update_success = update_jsm_config(result['url'])
    log_message(
        f"[{'æˆåŠŸ' if update_success else 'å¤±è´¥'}] jsmé…ç½®æ›´æ–°å®Œæˆ",
        step="ä¸»æµç¨‹"
    )

    # ç»Ÿè®¡æŠ¥å‘Š
    log_message(
        f"[å®Œæˆ] å¤„ç†ç»“æžœ: {stats['success']}/{stats['total']} æˆåŠŸ\n"
        f"url.jsonå˜æ›´é¡¹ ({len(stats['changed'])}):\n" + "\n".join(stats['changed']) + "\n"
        f"url.jsonå¤±è´¥é¡¹ ({len(stats['failed'])}): {', '.join(stats['failed']) if stats['failed'] else 'æ— '}",
        step="ç»Ÿè®¡æŠ¥å‘Š"
    )
    return stats['success'] > 0


def main():
    warnings.simplefilter('ignore', InsecureRequestWarning)
    process_urls()


if __name__ == "__main__":
    start_time = time.time()
    main()
    elapsed = time.time() - start_time
    print(f"æ€»è€—æ—¶: {elapsed:.2f}ç§’")

